\section{Stream Analytics und Complex Event Processing}
Stream Analytics beschreibt grundlegend das Analysieren und Verarbeiten von Datenströmen, allerdings zur Laufzeit und nahezu in Echtzeit. Das bedeutet, dass die Zeit zwischen Datenaufnahme und Ergebnissen möglichst gering ist. Typischerweise wird dies in Sekunden gemessen. Grundsätzlich geht es bei der Verarbeitung um das Filtern, Aggregieren und Suchen von Mustern. Die Resultate lassen sich anschließend an entsprechende Anwendungen weiterleiten. Stream Analytics gehört somit zum Themenbereich von Complex Event Processing \cite{GesellschaftfurInformatik.2009}.\\ \\ 
Complex Event Processing ist ein Sammelbegriff. Dieser umfasst Methoden, Techniken und verschiedene Werkzeuge, mit denen voneinander unabhängige Ereignisse stetig und zeitnah verarbeitet werden können. Um auf Ereignisse zu reagieren, werden aus dem eingehenden Datenstrom benötigte Informationen extrahiert. Typische Reaktionen wären das Senden von Benachrichtigungen, einfache Aktionen oder Interaktionen mit Geschäftsprozessen \cite{GesellschaftfurInformatik.2009}. Es können mehrere einzelne Ereignisse verbunden werden, sodass sie ein komplexes Ereignis ergeben. Für verschiedene Situationen ist es zudem notwendig, dass Ereignisse in einem gewissen Zeitraum bzw. einer bestimmten Reihenfolge auftreten. Somit sind zeitliche Zusammenhänge ebenfalls von Bedeutung. Da der Ereignisstrom unendlich ist, sind Abfragen nur in bestimmten Ausschnitten (Fenstern) denkbar \cite{GesellschaftfurInformatik.2009}. \\ \\
Da Datenströme häufig aus einem großen teil irrelevanter Daten („noise“) besteht und nur zu einem Bruchteil aus Nutzdaten („signal“), müssen diese Wichtigen Daten über geeignete Filtermechanismen herausgefiltert werden. Dies ermöglicht eine Konzentration der relevanten Anteile, während beispielsweise Messfehler direkt aussortiert werden können. Nachfolgend werden die relevanten Teile mit anderen Datenströmen in Bezug gebracht. Durch diese Korrelation der einzelnen Sensordaten können Situationen erstellt werden. Zusätzlich zu dieser Korrelation können die Daten mit Informationen aus unterschiedlichen Datenbanken angereichert werden. Dies kann nützlich sein, um noch aussagekräftigere Ergebnisse zu erzielen. Dabei ist vor allem die zeitliche Komponente der Ereignisse ein wichtiger Faktor. Da Ereignisse, die in einem bestimmten Zeitraum passieren von großer Bedeutung sein können, gibt es die Funktion der Zeitfenster, wodurch auf einen gewissen Abschnitt Funktionen angewandt werden können. Nach dieser Vorverarbeitung des Ereignisstroms lassen sich die Daten gezielt nach definierten Mustern absuchen. Werden entsprechende Muster gefunden, kann das System darauf reagieren. Hier liegt der eigentliche Wert der Technologie \cite{Bruening.2016}.



% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi